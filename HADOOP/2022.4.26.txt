수집방법(data)
batch : 일괄처리(mapreduce, spark)
realtime : 실시간(flume,kafka,splunk)

머신러닝 홈페이지
https://scikit-learn.org/stable/index.html

hadoop fs -ls / : 하둡 사용자 계정확인

하둡분산파일시스템 
- 파일을 기본 64~128M 단위로 나누어 분산 저장
- 네임노드와 데이터노드로 분리 구성

맴리듀스
- 대용량데이터를 빠르고 안전하게 병렬처리 할 수 있도록 상용 하드웨어를 이용한 분산프로그래밍 모델




하둡설치
참고사이트: 
https://hadoop.apache.org/docs/r3.2.3/hadoop-project-dist/hadoop-common/SingleCluster.html

wget http://mirror.apache-kr.org/hadoop/common/hadoop-3.2.3/hadoop-3.2.3.tar.gz
sudo tar xvf ./hadoop-3.2.3.tar.gz -C /usr/sbin/
vi ~/.bashrc
export HADOOP_HOME=/usr/sbin/hadoop-3.2.3
export PATH=$PATH$JAVA_HOME/bin:$HADOOP_HOME/bin/:$HADOOP_HOME/sbin
source ~/.bashrc


하둡java환경변수연결
cd /usr/sbin/hadoop-3.2.3/etc/hadoop
vi haddop-env.sh
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64


하둡 dfs single.node 설정

vi core-site.xml:
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>


vi hdfs-site.xml:
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>


vi mapred-site.xml:
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>mapreduce.application.classpath</name>
        <value>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*</value>
    </property>
</configuration>


하둡 yarn single.node 설정

vi yarn-site.xml:
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ,HADOOP_MAPRED_HOME</value>
    </property>
</configuration>


ssh비번 초기화
  $ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
  $ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
  $ chmod 0600 ~/.ssh/authorized_keys

아파치 설치
참고 사이트 : https://www.digitalocean.com/community/tutorials/how-to-install-the-apache-web-server-on-ubuntu-20-04
sudo apt update
sudo ufw allow 'Apache'
sudo ufw status
sudo systemctl status apache2

네임노드포멧
hdfs namenode -format

유저생성
/usr/sbin/hadoop-3.2.3/bin/hdfs dfs -mkdir /user

서버시작
start-dfs.sh
start-yarn.sh
mapred --daemon start historyserver

hadoop 파일시스템확인
hadoop fs -ls /

서버스탑
stop-dfs.sh
stop-yarn.sh
mapred --daemon stop historyserver


adduser user01
usermod -aG sudo user01

네임노드
http://localhost:9870

리소스매니저
http://localhost:8088

히스토리 서버
http://localhost:19888
